\documentclass{sig-alternate-05-2015}
\usepackage{float}
\usepackage{hyperref}


\begin{document}
% Copyright
%\setcopyright{acmcopyright}
% DOI
\doi{000000}

% ISBN
\isbn{000000}

\title{Access to Big Data in Bioinformatics}
% \subtitle{[Extended Abstract]}

\numberofauthors{1}
\author{
\alignauthor
Andrew van Rooyen\\
       \affaddr{University of Cape Town}\\
}

\date{30 August 2015}

\toappear{
	This paper and associated code is available at \url{https://github.com/wraithy/bigbinf}\\
	The OpenSSH-Portable installation used for HPN-SSH was compiled frm \url{https://github.com/rapier1/openssh-portable}\\
	The large hg38.fa.align.gz dataset used is available at \url{http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/}\\
	For more information, please see \url{pubs.cs.uct.ac.za}
}

\maketitle
\begin{abstract}
	TODO
\end{abstract}
% \keywords{Big Data; BioInformatics; Clouds}


\section{Introduction}
Next generation sequencing has resulted in a massive increase in the size of bioinformatics datasets, which can be tens of gigabytes in size~\cite{deorowicz2011compression}. Sequencing technologies like SOLiD provide much higher data output at a cheaper cost~\cite{shendure2008next}, which creates challenges in data storage, transfer and access. In fact, the cost of storing a byte has been higher than sequencing a base pair since before 2010~\cite{baker2010next}.

Generally, sequence data is stored in a data warehouse. Storing this information for long periods of time requires the data to be structured efficiently in order to save space and to allow it to be transferred efficiently.

There are a plethora of sequence file formats whose efficiency depends on the kind of data stored. Two of the most popular are FASTQ, which stores aggregated reads along with the quality of each DNA base pair~\cite{cock2010sanger}, and BAM, the binary, compressed version of the Sequence Alignment Map (SAM) format~\cite{SAMspec}.

Researchers often require access to the data warehouses to transfer the sequences they need. Luckily, these locations are often connected by massive data pipes like National Research and Education Networks (NREN's). For example, South African universities are connected by the South African National Research Network \cite{sanren} which runs at 10Gbps. Unfortunately, standard transfer protocols like FTP and SSH were not designed for use on high-throughput networks, and alternate protocols must be used to avoid bottlenecks.

Some proprietary transfer protocols are widely used in practice - for example, the \textit{fasp} protocol by the US based company AsperaSoft. Based on UDP, this protocol eliminates the latency issues seen with TCP, and provides transfer bandwidth of up to 10 gigabits per second~\cite{beloslyudtsev2014aspera}.

There have been some attempts to avoid data transfer altogether. This means processing data remotely, and there has been an explorative push towards cloud solutions from companies such as Amazon and Google~\cite{baker2010next}. Unfortunately, even though cloud data centres have plenty of cheap storage, the transfer bottleneck remains as researchers must still upload their raw data to the cloud data centres every time they run a new experiment. Some researchers have even resorted to mailing hard drives~\cite{baker2010next}.

There are also security, privacy and ethical concerns with outsourcing processing power to other companies, as sequenced DNA data is often highly sensitive information~\cite{marx2013biology}.

In this work, we compare the GridFTP, FTP, HPN-SSH and SSH file transfer protocols to determine which is best for transferring bioinformatics data on an educational network. These are the most popular protocols for file transfer in the field, perhaps with the exception of AsperaSoft's \textit{fasp}, which is non-free. 

In order to test the protocols in a relevant environment, the tests are run between the University of Cape Town (UCT) and the University of the Western Cape (UWC) which are connected via SANReN.

\section{Methods}
The transfer protocols are tested to establish measures of speed, data overhead and packet size. Transfers are run periodically at various hours of the day.

\subsection{Protocols}
The OpenSSH~\cite{openssh} implementations of FTP (sftp) and SSH (scp) are tested. High Performance SSH (HPN-SSH) is a set of patches to OpenSSH which removes bottlenecks~\cite{rapier2008high}. The scp binary from a patched, portable version of OpenSSH is tested for HPN. This is installed alongside the original so that both binaries are available.

The `lite' version of GridFTP~\cite{allcock2005globus} is used. This means that authentication is done via ssh as opposed a previously-configured certificate authority. This makes no difference to the file transfer itself, but it prevents unnecessary configuration of the testbed which can be quite complex in the case of `full' GridFTP~\cite{gridftplite}.

Once the ideal protocol is decided on, it is made available as an endpoint to the microcloud system, so that users can retrieve their results in an optimal way.

\subsection{Approach}
Transfers using each of the four protocols are run while the network traffic is logged.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.4\textwidth]{img/route.png}
	\caption{The hosts in their environment.
	         \label{fig:route}}
\end{figure}

The hosts are virtual machines running at the South African National Bioinformatics Institute (UWC) and the Science DMZ (UCT). Both locations are close to the SANReN link, and outside institutional firewalls as depicted in Figure \ref{fig:route}. This means that throttling is avoided, and ensures a minimum speed of 1Gbps.

The testing environment is kept as stable as possible during tests, and multiple tests are run at different times of the day.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.4\textwidth]{img/transfer_example.png}
	\caption{Host 1 copying a file and capturing packets
	         \label{fig:copy_example}}
\end{figure}
For each transfer, a copy is initiated from Host 1. A file from Host 2 is transferred to Host 1 using the particular protocol (see Figure \ref{fig:copy_example}).

The tests are run with 3 files: A 6 byte file containing the word `hello', a 350MB video file and a 2.4 GB gzipped sequence alignment file. Even though the protocols are agnostic of file format (they treat everything as binary), the 2.4GB file is a typical dataset that researchers would need.

The `tcpdump' program (\url{www.tcpdump.org}) comes with most Unix systems. As depicted in Figure \ref{fig:copy_example}, it watches a network interface (e.g.\ eth0) and logs information about packets which pass through. The program is run while each transfer is in progress, and the output is filtered to include only packets sent between Host 1 and Host 2. This output is used as the raw data for analysis.

This approach allows analysis of transfer overhead (because \textit{all} transferred data is logged, rather than just the file size), speed (data/time), consistency, total time, and total size.

Note that despite the name, tcpdump can also capture UDP packets, which is relevant if GridFTP is run in UDT mode~\cite{gu2007udt}. This is an alternate protocol built on top of UDP which aims to overcome congestion control bottlenecks found in TCP. Although Bresnahan et. al. found that GridFTP's UDT mode outperformed the TCP mode~\cite{bresnahan2009udt}, both modes are still tested.

\subsection{Implementation of Testbed}
A simple Python script is sufficient to run the transfers, as most of the work is done by a subprocess for each specific protocol. The analysis is also done with Python, as there are a vast number of analytical and visualisation tools available.

All testing is done on an Ubuntu 14.04 system, with the respective transfer programs installed. 

The Python script for running the file transfers has been written to accept: the name of the network interface, the remote hostname (Host 2), the path of the file on Host 2, and a local path to copy the file to.
It then resolves the IPs of each host, and for each protocol, runs a transfer in isolation. 
\begin{figure}[t]
	\centering
	\includegraphics[height=0.5\textheight]{img/seq_example}
	\caption{The sequence of subprocesses called by the testbed.
	         \label{fig:testbed_sequence}}
\end{figure}
As shown in Figure \ref{fig:testbed_sequence}, it spawns a tcpdump subprocess which runs for precisely as long as the copy runs. The tcpdump program is started with filters, so that only traffic between the two hosts is captured. It then saves the output in a file.

This allows for a controlled environment, because the tcpdump only captures while the copy is running, no other packets are included in the logs. Also, the copies are run programmatically and consecutively. Successive copies are not started until both the tcpdump and protocol processes have been closed, and the log file has been written. This means that they are all run in an identical (within reason) environment, but at the same time do not interfere with each other.

This test process is run multiple times for statistical reasons, generating multiple log files.

A separate Python file then reads in the log files and parses them. This information is used to calculate metrics and display graphs.
Operations can then be run by looking at the time of each packet, and the size of its payload. 

This data can then be aggregated over multiple log files, and graphed using the matplotlib Python library.

\section{Results}
Please note that the following data was not collected from the final tests. It represents a test run between my lab machine at UCT, and my DigitalOcean VM in a datacenter in Amsterdam. The environment was not controlled, and the connection was absolutely \textit{not} stable. In fact, you are able to see this from the graph depicting individual packets. This section will be replaced with real data, and just serves to demonstrate the \textit{kinds} of graphs that can be included. 

\begin{figure*}
	\centering
	\includegraphics[height=\textheight]{img/testdata_packets.png}
	\caption{A graphical representation of each transfer
	         \label{fig:testdata_packets}}
\end{figure*}
Figure \ref{fig:testdata_packets} shows each packet of the transfer as a dot, where the x axis is time and the y axis shows the payload length in bytes.

\begin{figure*}
	\centering
	\includegraphics[width=\textwidth]{img/testdata_detail.png}
	\caption{The raw data, aggregated per protocol
	         \label{fig:testdata_detail}}
\end{figure*}
Figure \ref{fig:testdata_detail} is what the analysis suite outputs if no arguments for graphs are specified. It is representing the same data, but shows it in a way which is easier to see actual values.

\begin{figure*}
	\centering
	\includegraphics[width=\textwidth]{img/testdata_aggregate.png}
	\caption{Aggregated data per protocol, with a line representing filesize
	         \label{fig:testdata_aggregate}}
\end{figure*}

Figure \ref{fig:testdata_aggregate} shows the same data as Figure \ref{fig:testdata_detail}, but displayed as a bar graph. This facilitates easier comparison between protocols, and makes it easy to see how much overhead (or compression) was used by comparing the bars to the filesize line.

\section{Acknowledgements}
TODO

\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{ref} 


\end{document}

